{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpSOLWKvZEbJ",
        "outputId": "4d9cadb2-1f53-4e93-fd91-33b2b08d3c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 1:\n",
            "Sentiment: Positive\n",
            "Key Phrases: ['I', 'a team environment', 'others', 'My last job', 'a great experience', 'the supportive and dynamic team', 'I']\n",
            "Overall Quality: Good\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Response 2:\n",
            "Sentiment: Negative\n",
            "Key Phrases: ['I', 'a fan', 'tight deadlines', 'They', 'me', 'a lot', 'stress', 'I', 'the quality', 'my work', 'a result']\n",
            "Overall Quality: Average\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Response 3:\n",
            "Sentiment: Positive\n",
            "Key Phrases: ['I', 'my greatest strength', 'my attention', 'detail', 'I', 'my work', 'which', 'me', 'mistakes', 'high-quality results']\n",
            "Overall Quality: Good\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Response 4:\n",
            "Sentiment: Positive\n",
            "Key Phrases: ['I', 'new technologies', 'them', 'real-world problems', 'I', 'a course', 'machine learning', 'I', 'these skills', 'my next role']\n",
            "Overall Quality: Good\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import spacy #for natural language processing (NLP) tasks\n",
        "from textblob import TextBlob #for sentiment analysis\n",
        "\n",
        "# here we load a small pretrained English model('en_core_web_sm') from spaCy for NLP tasks.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Sample interview responses genetated from AI\n",
        "responses = [\n",
        "    \"I really enjoy working in a team environment and collaborating with others. My last job was a great experience because of the supportive and dynamic team I worked with.\",\n",
        "    \"I am not a fan of tight deadlines. They often cause me a lot of stress, and I feel that the quality of my work suffers as a result.\",\n",
        "    \"I believe my greatest strength is my attention to detail. I always make sure to check my work thoroughly, which helps me avoid mistakes and deliver high-quality results.\",\n",
        "    \"I'm really passionate about learning new technologies and applying them to solve real-world problems. I recently completed a course on machine learning, and I'm excited to use these skills in my next role.\"\n",
        "]\n",
        "# Creating a function to analyze response\n",
        "def analyze_response(response):\n",
        "\n",
        "    # sentiment analysis using TextBlob lib\n",
        "    blob = TextBlob(response) #Creating an object for response\n",
        "    sentiment_score = blob.sentiment.polarity #computes the sentiment polarity score of the text\n",
        "\n",
        "    # determine sentiment category based on polarity score\n",
        "    if sentiment_score > 0:\n",
        "        sentiment = 'Positive'\n",
        "    elif sentiment_score < 0:\n",
        "        sentiment = 'Negative'\n",
        "    else:\n",
        "        sentiment = 'Neutral'\n",
        "\n",
        "    # Extract key phrases using spaCy's noun_chunks (noun phrases)\n",
        "    doc = nlp(response)\n",
        "    key_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
        "\n",
        "    return sentiment, key_phrases #returns a tuple containing the sentiment category and the list of key phrases extracted from the response\n",
        "\n",
        "def overall_quality_assessment(sentiment, key_phrases):\n",
        "\n",
        "    # rules to determine quality based on sentiment and presence of key phrases\n",
        "    if sentiment == 'Positive' and key_phrases:\n",
        "        quality = 'Good'\n",
        "    elif sentiment == 'Negative' and not key_phrases:\n",
        "        quality = 'Poor'\n",
        "    else:\n",
        "        quality = 'Average'\n",
        "    return quality\n",
        "\n",
        "# run a loop through each response and analyze it\n",
        "for idx, response in enumerate(responses):\n",
        "    sentiment, key_phrases = analyze_response(response)  #takes sentiment and key phrases\n",
        "    quality = overall_quality_assessment(sentiment, key_phrases)  #now assess the overall quality\n",
        "\n",
        "    # Print the results for each response\n",
        "    print(f\"Response {idx + 1}:\")\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "    print(f\"Key Phrases: {key_phrases}\")\n",
        "    print(f\"Overall Quality: {quality}\")\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
      ]
    }
  ]
}